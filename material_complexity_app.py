"""
ì¬ì§ˆ ë³µì¡ë„ ì¸¡ì •ê¸°
Material Complexity Analyzer

H (Permutation Entropy) - ë¬´ì§ˆì„œë„
C (Statistical Complexity) - êµ¬ì¡°ì  ë³µì¡ë„  
F (Fisher Information) - ê²½ê³„ ì„ ëª…ë„
"""

import streamlit as st
import numpy as np
from PIL import Image
from hilbertcurve.hilbertcurve import HilbertCurve
from math import factorial  # â† ì—¬ê¸° ìˆ˜ì •!
import itertools
import io

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¬ì§ˆ ë³µì¡ë„ ì¸¡ì •ê¸°",
    page_icon="ğŸ¨",
    layout="wide"
)

# ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 1rem 0;
    }
    .metric-card-h {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    }
    .metric-card-c {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
    }
    .metric-card-f {
        background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);
    }
    .metric-value {
        font-size: 3rem;
        font-weight: 700;
        margin: 0.5rem 0;
    }
    .metric-label {
        font-size: 1.2rem;
        opacity: 0.9;
    }
    .metric-desc {
        font-size: 0.9rem;
        opacity: 0.8;
        margin-top: 0.5rem;
    }
    .interpretation {
        padding: 1rem;
        border-radius: 8px;
        margin-top: 1rem;
        font-weight: 500;
    }
    .interpretation-low {
        background-color: #e8f5e9;
        color: #2e7d32;
    }
    .interpretation-medium {
        background-color: #fff3e0;
        color: #e65100;
    }
    .interpretation-high {
        background-color: #fce4ec;
        color: #c2185b;
    }
    .recommendation-box {
        background-color: #e3f2fd;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #1976d2;
        margin: 2rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: 600;
        padding: 0.75rem;
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)


def hilbert_to_sequence(image_array, size=512):
    """2D ì´ë¯¸ì§€ë¥¼ Hilbert Curveë¡œ 1D ì‹œí€€ìŠ¤ ë³€í™˜"""
    # Grayscale ë³€í™˜
    if len(image_array.shape) == 3:
        gray = 0.299 * image_array[:,:,0] + 0.587 * image_array[:,:,1] + 0.114 * image_array[:,:,2]
    else:
        gray = image_array
    
    # 512x512 ë¦¬ì‚¬ì´ì¦ˆ
    img_pil = Image.fromarray(gray.astype('uint8'))
    img_pil = img_pil.resize((size, size))
    img_array = np.array(img_pil, dtype=float)
    
    # Hilbert Curve ìƒì„±
    n = int(np.log2(size))
    hilbert = HilbertCurve(n, 2)
    
    # 1D sequence ì¶”ì¶œ
    sequence = []
    for i in range(size * size):
        coords = hilbert.point_from_distance(i)
        pixel_value = img_array[coords[1], coords[0]]
        sequence.append(pixel_value)
    
    return np.array(sequence)


def ordinal_patterns(sequence, D=5, tau=1):
    """Bandt-Pompe ordinal patterns ìƒì„±"""
    N = len(sequence)
    patterns = []
    
    # ë¶€ë¶„ ì‹œí€€ìŠ¤ ì¶”ì¶œ ë° íŒ¨í„´ ë³€í™˜
    for t in range(N - (D-1)*tau):
        sub_seq = [sequence[t + i*tau] for i in range(D)]
        pattern = tuple(np.argsort(sub_seq))
        patterns.append(pattern)
    
    # í™•ë¥  ë¶„í¬ ê³„ì‚°
    unique_patterns, counts = np.unique(patterns, axis=0, return_counts=True)
    total = len(patterns)
    
    pattern_probs = {}
    for pattern, count in zip(unique_patterns, counts):
        pattern_probs[tuple(pattern)] = count / total
    
    return patterns, pattern_probs


def permutation_entropy(pattern_probs, D=5, normalize=True):
    """H (Permutation Entropy) ê³„ì‚°"""
    # Shannon Entropy
    S = 0
    for prob in pattern_probs.values():
        if prob > 0:
            S -= prob * np.log(prob)
    
    # ì •ê·œí™”
    if normalize:
        max_entropy = np.log(factorial(D))
        H = S / max_entropy
    else:
        H = S
    
    return H


def statistical_complexity(pattern_probs, D=5):
    """C_JS (Statistical Complexity) ê³„ì‚°"""
    # P_e: ê· ë“± ë¶„í¬
    num_patterns = int(factorial(D))  # â† int() ì¶”ê°€!
    p_e = 1.0 / num_patterns
    
    # P ë¶„í¬ (ì‹¤ì œ)
    P = np.zeros(num_patterns)
    for i, pattern in enumerate(itertools.permutations(range(D))):
        if pattern in pattern_probs:
            P[i] = pattern_probs[pattern]
        else:
            P[i] = 0
    
    # P_e ë¶„í¬
    P_e = np.ones(num_patterns) * p_e
    
    # Jensen-Shannon Divergence
    def shannon_entropy(probs):
        S = 0
        for p in probs:
            if p > 0:
